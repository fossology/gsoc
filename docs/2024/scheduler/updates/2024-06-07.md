---
title: OVERHAULING SCHEDULER DESIGN (Discussion)
author: Aaditya Singh
---
<!--
SPDX-License-Identifier: CC-BY-SA-4.0

SPDX-FileCopyrightText: 2024 Aditya Singh <singh.aaditya889@gmail.com>
--> 

# Meeting 4

*(June 07, 2024)*

## Attendees:

  - [Katharina Ettinger](https://github.com/EttingerK)

  - [Shaheem Azmal M MD](https://github.com/shaheemazmalmmd)

  - [Gaurav Mishra](https://github.com/GMishx)

  - [Kaushlendra Pratap](https://github.com/Kaushl2208)

  - [Avinal](https://github.com/avinal)

  - [Aaditya Singh](https://github.com/Aaditya-Singh78)

## Discussion:

### Contributor:

- [Aaditya Singh](https://github.com/Aaditya-Singh78):

### Mentor:

-  [Shaheem Azmal M MD](https://github.com/shaheemazmalmmd): Can priority be implemented in both dependent and independent queues?

-  [Gaurav Mishra](https://github.com/GMishx): There are several considerations to take into account, such as:

1. Fossology aims to ensure mutual exclusivity either across dependent queues, independent queues, or both.

2. Each job instance requires execution one at a time, adhering to the rule of processing 60 requests per time frame, and there is a lack of a distributed database system.

How would you try to achieve with this architecture?

-  [Kaushlendra Pratap](https://github.com/Kaushl2208):How can goroutines achieve both concurrency and parallelism, whether synchronously or asynchronously?

### Setting Priority in Distributed Queue:

### Mutual Exclusivity across Distributed Queue:


### Connecting Distributed Scheduler with Centralised Database:

> ⚠️ **Warning:** 
This issue was highlighted during the meeting, and after further research, I have come up with a solution.


[Aaditya Singh](https://github.com/Aaditya-Singh78): I'm considering utilizing Redis as middleware between a distributed scheduler and a centralized database by integrating it with a Multi-Level Feedback Queue (MLFQ) based distributed scheduler. This approach offers a substantial enhancement in managing complex task scheduling and system performance, particularly in comparison to the limitations of CronJobs in a Kubernetes setting due to:

1. **Concurrency Control with Redis**: Redis employs mechanisms such as SETNX or the RedLock algorithm, which are essential for ensuring that only one instance of any job runs across the distributed system. This is critical for preserving the integrity of job executions within your scheduler.
2. **Advanced Caching & State Management**: Redis effectively caches frequently accessed data, like job statuses and metadata. This minimizes direct database interactions, aids in maintaining rate limits, and enhances the response times for job status queries. Additionally, Redis serves as a central hub for state sharing among distributed nodes, facilitating rapid synchronization of job states without continuous database queries, which is vital for maintaining a responsive scheduler.
3. **Job Queue Management**: Leveraging Redis' pub/sub capabilities enables efficient job queue management across multiple scheduler instances, ensuring that jobs are evenly distributed and managed throughout your system.

However, there are several reasons for setting aside CronJobs:

1. **Static Time-Based Scheduling**: CronJobs are designed for tasks that need to run at predetermined times, lacking the necessary flexibility for jobs where priority and resource requirements may vary based on real-time data or user demands.
2. **Non-Dynamic Resource Management**: CronJobs do not adjust or prioritize tasks based on the current system load or task urgency, rendering them unsuitable for environments that demand resource adaptability.

### Concurrency & Parallelism:

