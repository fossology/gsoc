---
title: Week 5
author: Shreya Gautam
tags: [gsoc24, pipeline]
---

<!--
SPDX-License-Identifier: CC-BY-SA-4.0

SPDX-FileCopyrightText: 2024 Shreya Gautam <gautamm.shreya@gmail.com>
-->

# WEEK 5
*(June 27, 2024)*

## Attendees:
- [Kaushlendra Pratap](https://github.com/Kaushl2208)
- [Gaurav Mishra](https://github.com/GMishx)
- [Shaheem Azmal M MD](https://github.com/shaheemazmalmmd)
- [Ayush Bhardwaj](https://github.com/hastagAB)
- [Avinal Kumar](https://github.com/avinal)

## Discussion:
* Checked use cases to evaluate the current model's preprocessing output and discussed findings.
  Checking of corner cases can be found [here](https://github.com/ShreyaGautamm/gsoc_24/blob/1a2ded0c4a06691ab185e012fad39e401d6429b1/files/testing_corner_cases.ipynb) and my findings can be found documented in this [word file](https://docs.google.com/document/d/1h13ydbpDG6voXgX45gTHwtvtK_4bvK8j-JXH9vkh4R4/edit?usp=sharing).
  
* I [researched](https://docs.google.com/document/d/1h13ydbpDG6voXgX45gTHwtvtK_4bvK8j-JXH9vkh4R4/edit?usp=sharing) and explored various NER taggers and began creating a library for NER-POS tagging using Stanford's NER tagger. In parallel, I initiated work on developing a dedicated library for this task and investigated multiple models: 
  - SpaCy
  - NLTK
  - Flair
  - Stanford’s CoreNLP
  - AllenNLP
  - Apache OpenNLP

I tested Stanford’s CoreNLP with some random data from the internet to evaluate its model. You can find my code for experimentation [here](https://github.com/ShreyaGautamm/gsoc_24/blob/91e79fac9fda07148034ae927701306e7baedbd5/files/ner/Stanford_Tagger.ipynb).

* I wrote a Python script using Psycopg to connect to the Fossology database and retrieve copyright contents. During this process, I encountered and addressed several issues. You can find the script [here](https://github.com/ShreyaGautamm/gsoc_24/blob/4fd6f5813340b2d5b3aac5823e1d0539a30391d9/files/copyrights_script.ipynb).

## Subsequent Steps
* The mentors emphasized the critical importance of completing the framework before progressing further. Therefore, my plan for the next week is to focus on getting the framework ready.
* In the NER tagging task, I plan to focus on fine-tuning BERT to perform both NER and POS tagging tasks. Multitask learners, like fine-tuned language models, generally achieve better performance on downstream tasks.
